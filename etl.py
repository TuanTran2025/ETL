# -*- coding: utf-8 -*-
"""etl.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1GR94EuWMBxJpNQBjbppUDSAzrczARbJl
"""

# etl.py

# -----------------------------
# !pip install pandas sqlalchemy pymysql openpyxl requests
# -----------------------------

import os
import pandas as pd
import requests
from sqlalchemy import create_engine
import pymysql

# -----------------------------
# Helper function to download files
# -----------------------------
def download_file(url, filename):
    response = requests.get(url)
    with open(filename, 'wb') as f:
        f.write(response.content)

# -----------------------------
# Step 1: Extract
# -----------------------------
# Download Excel and CSV files
download_file("https://sca-programming-school.github.io/datasets/enrollies_education.xlsx", "enrollies_education.xlsx")
download_file("https://sca-programming-school.github.io/datasets/work_experience.csv", "work_experience.csv")

# Read from Google Sheets
sheet_id = '1VCkHwBjJGRJ21asd9pxW4_0z2PWuKhbLR3gUHm-p4GI'
gs_url = f'https://docs.google.com/spreadsheets/d/{sheet_id}/export?format=xlsx'
enrollies_data = pd.read_excel(gs_url, sheet_name='enrollies')

# Local files
enrollies_education = pd.read_excel("enrollies_education.xlsx")
work_experience = pd.read_csv("work_experience.csv")

# MySQL source
mysql_engine = create_engine('mysql+pymysql://etl_practice:550814@112.213.86.31:3360/company_course')
training_hours = pd.read_sql_table('training_hours', mysql_engine)
employment = pd.read_sql_table('employment', mysql_engine)

# Web data
tables = pd.read_html('https://sca-programming-school.github.io/city_development_index/index.html')
cities = tables[0]

# -----------------------------
# Step 2: Transform
# -----------------------------
# Convert data types and fill missing values
enrollies_data['full_name'] = enrollies_data['full_name'].astype('string')
enrollies_data['city'] = enrollies_data['city'].astype('category')
enrollies_data['gender'] = enrollies_data['gender'].astype('category')
enrollies_data['gender'].fillna(enrollies_data['gender'].mode()[0], inplace=True)

enrollies_education['enrolled_university'] = enrollies_education['enrolled_university'].astype('category')
enrollies_education['education_level'] = enrollies_education['education_level'].astype('category')
enrollies_education['major_discipline'] = enrollies_education['major_discipline'].astype('category')
enrollies_education['enrolled_university'].fillna(enrollies_education['enrolled_university'].mode()[0], inplace=True)
enrollies_education['education_level'].fillna(enrollies_education['education_level'].mode()[0], inplace=True)
enrollies_education['major_discipline'].fillna(enrollies_education['major_discipline'].mode()[0], inplace=True)

work_experience['company_type'] = work_experience['company_type'].astype('category')
work_experience['company_size'] = work_experience['company_size'].astype('category')
work_experience['experience'].fillna(work_experience['experience'].mode()[0], inplace=True)
work_experience['company_type'].fillna(work_experience['company_type'].mode()[0], inplace=True)
work_experience['company_size'].fillna(work_experience['company_size'].mode()[0], inplace=True)
work_experience['last_new_job'].fillna(work_experience['last_new_job'].mode()[0], inplace=True)

cities['City'] = cities['City'].astype('string')

# -----------------------------
# Step 3: Load to SQLite warehouse
# -----------------------------
sqlite_engine = create_engine('sqlite:///data_warehouse.db')

enrollies_data.to_sql('dim_enrollies', sqlite_engine, if_exists='replace', index=False)
enrollies_education.to_sql('fact_enrollies_education', sqlite_engine, if_exists='replace', index=False)
work_experience.to_sql('dim_work_experience', sqlite_engine, if_exists='replace', index=False)
training_hours.to_sql('dim_training_hours', sqlite_engine, if_exists='replace', index=False)
cities.to_sql('dim_cities', sqlite_engine, if_exists='replace', index=False)
employment.to_sql('dim_employment', sqlite_engine, if_exists='replace', index=False)

print("ETL process completed successfully.")